% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/normal_clustering.R
\name{mcmc_out}
\alias{mcmc_out}
\title{MCMC out}
\usage{
mcmc_out(MS_object, class_labels_0 = NULL, mu_0 = NULL, df_0 = NULL,
  scale_0 = NULL, lambda_0 = 0.01, concentration_0 = NULL,
  cat_data = NULL, cluster_weight_priors_categorical = 1,
  phi_0 = NULL, c_clusters_label_0 = NULL, num_clusters_cat = 100,
  train = NULL, num_iter = NULL, burn = NULL, thinning = 25,
  heat_plot = TRUE, main = "heatmap_for_similarity", cluster_row = T,
  cluster_cols = T, fontsize = 10, fontsize_row = 6,
  fontsize_col = 6, entropy_plot = TRUE, window_length = min(25,
  num_iter/5), mean_tolerance = 5e-04, sd_tolerance = 5e-04,
  sense_check_map = TRUE, outlier = FALSE, t_df = 4,
  prediction_threshold = 0.6, record_posteriors = FALSE,
  normalise = FALSE)
}
\arguments{
\item{MS_object}{A dataset in the format used by pRolocdata.}

\item{class_labels_0}{An optional prior for clusters in MS_object. If NULL
defaults to a randomly generated set using the proportion in the labelled
data.}

\item{mu_0}{A d-vector; prior on mean. If NULL defaults to mean of data.}

\item{df_0}{The prior on the degrees of freedom. if NULL defaults to d + 2.}

\item{scale_0}{The prior on the scale for the Inverse Wishart. If NULL
generated using an empirical method.}

\item{lambda_0}{The prior of shrinkage for mean distribution.}

\item{concentration_0}{The prior for dirichlet distribution of cluster
weights.}

\item{cat_data}{Matrix of 1's and 0's used for multiple dataset integration,
Default is NULL in which case a generic mixture of Gaussians is used.}

\item{cluster_weight_priors_categorical}{Vector of the prior on cluster
weights in the categorical data.}

\item{phi_0}{List of vectors, the prior on the distribution of the classes
over clusters.}

\item{c_clusters_label_0}{Vector of labels for the prior clustering of the
categorical data.}

\item{num_clusters_cat}{Integer of the number of clusters to have as a
maximum in the categorical dataset. Default is 100.}

\item{num_iter}{The number of iterations to sample over.}

\item{burn}{The number of iterations to record after (i.e. the burn-in).}

\item{thinning}{The step between iterations for which results are recorded in
the mcmc output.}

\item{heat_plot}{A bool. Instructs saving and printing of heatmap of
similarity matrix from Gibbs sampling. Default is TRUE.}

\item{main}{String. The title for heatmap, default is "heatmap_for_similarity".}

\item{cluster_row}{A bool. Instructs pheatmap to cluster rows using a tree.}

\item{entropy_plot}{A bool instructing function to save a plot of the entropy
across all iterations. Default is TRUE.}

\item{window_length}{A number. Input to entropy ploy function. Default is
min(25, num_iter / 5).}

\item{mean_tolerance}{Input to entropy ploy function. Default is 0.0005.}

\item{sd_tolerance}{Input to entropy ploy function. Default is 0.0005.}

\item{outlier}{A bool instructing the sampler to consider an additional
outlier cluster following a t-distribution}

\item{t_df}{The degrees of freedom for the outlier t-distribution (default
is 4)}

\item{prediction_threshold}{The minimum proportion of recorded iterations
for which a point is in its most common cluster for which a prediction is
returned. If below this predicted class is NA.}

\item{record_posteriors}{A bool instructing the mcmc function to record the
posterior distributions of the mean and variance for each cluster
(default is FALSE)}

\item{normalise}{Bool instructing normalisation of continuous data (default
is false)}

\item{train:}{instruction to include all data (NULL), labelled data (TRUE) or
unlabelled data (FALSE). Default is NULL.}

\item{cluster_cols:}{A bool. instructs pheatmap to cluster columns using a
tree.}

\item{fontsize:}{The size of font in pheatmap.}

\item{fontsize_row:}{The fontsize in rows in pheatmap.}

\item{fontsize_col:}{The fontsize in columns in pheatmap.}
}
\value{
A named list including at least the output from the gibbs sampler,
but can include two pheatmaps and a scatter plot of the entropy over
iterations.
}
\description{
Returns mean, variance and similarity posteriors from Gibbs sampling with
option of pheatmap
}
\examples{
data("hyperLOPIT2015") # MS object from pRolocData
mcmc_object <- mcmc_out(hyperLOPIT2015,
  num_iter = 10000,
  burn = 1000,
  thinning = 50,
  outlier = TRUE,
  heat_plot = TRUE,
  main = "Gene clustering by organelle",
  prediction_threshold = 0.5
)

Generate some nonsense categorical data
cat_data <- matrix(nrow = 1371, ncol = 5)
cat_data[, 1] <- c(rep(1, 300), rep(0, 1071))
cat_data[, 2] <- c(rep(0, 300), rep(1, 300), rep(0, 771))
cat_data[, 3] <- c(rep(0, 600), rep(1, 300), rep(0, 471))
cat_data[, 4] <- c(rep(0, 800), rep(1, 300), rep(0, 271))
cat_data[, 5] <- c(rep(0, 1100), rep(1, 271))

# Complete noise
cat_data <-  matrix(sample(0:1, 1371 * 10, replace=TRUE), nrow = 1371, ncol = 10)

stuff <- mcmc_out(HEK293T2011,
                  cat_data = cat_data,
                  num_iter = 10,
                  burn = 1,
                  thinning = 1,
                  outlier = TRUE,
                  heat_plot = T,
                  main = "Gene clustering by organelle",
                  prediction_threshold = 0.4,
                  sense_check_map = F
)
}
